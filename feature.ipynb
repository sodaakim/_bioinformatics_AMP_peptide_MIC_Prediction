{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAC\n",
      "AAINDEX\n",
      "APAAC\n",
      "BINARY\n",
      "BLOSUM62\n",
      "CKSAAGP\n",
      "CKSAAP\n",
      "CTD_C\n",
      "CTD_D\n",
      "CTD_T\n",
      "CTriad\n",
      "DDE\n",
      "DPC\n",
      "EAAC\n",
      "EGAAC\n",
      "GAAC\n",
      "GDPC\n",
      "GTPC\n",
      "Geary\n",
      "Moran\n",
      "NMBroto\n",
      "PAAC\n",
      "QSOrder\n",
      "SOCNumber\n",
      "TPC\n",
      "ZSCALE\n",
      "checkFasta\n",
      "minSequenceLength\n",
      "minSequenceLengthWithNormalAA\n",
      "readFasta\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "import importlib.util\n",
    "\n",
    "module_path = 'ifeature_descriptor.py'\n",
    "module_name = 'ifeature_descriptor'\n",
    "\n",
    "spec = importlib.util.spec_from_file_location(module_name, module_path)\n",
    "module = importlib.util.module_from_spec(spec)\n",
    "spec.loader.exec_module(module)\n",
    "\n",
    "function_names = [name for name, obj in inspect.getmembers(module) if inspect.isfunction(obj)]\n",
    "for name in function_names :\n",
    "    print(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ifeature_descriptor.py에서 필요한 함수들을 불러옴\n",
    "for name in function_names:\n",
    "    globals()[name] = getattr(module, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import csv\n",
    "import os\n",
    "\n",
    "feature_types = [\n",
    "    \n",
    "    \"AAC\",\n",
    "    \"AAINDEX\",\n",
    "    \"APAAC\",\n",
    "    \"BINARY\",\n",
    "    \"BLOSUM62\",\n",
    "    \"CKSAAGP\",\n",
    "    \"CKSAAP\",\n",
    "    \"CTD_C\",\n",
    "    \"CTD_D\",\n",
    "    \"CTD_T\",\n",
    "    \"CTriad\",\n",
    "    \"DDE\",\n",
    "    \"DPC\",\n",
    "    \"EAAC\",\n",
    "    \"EGAAC\",\n",
    "    \"GAAC\",\n",
    "    \"GDPC\",\n",
    "    \"GTPC\",\n",
    "    \"Geary\",\n",
    "    \"Moran\",\n",
    "    \"NMBroto\",\n",
    "    \"PAAC\",\n",
    "    \"QSOrder\",\n",
    "    \"SOCNumber\",\n",
    "    \"TPC\"\n",
    "]\n",
    "FEATURE_FUNCTIONS = {feature: globals()[feature] for feature in feature_types if feature in globals()}\n",
    "# 피처 타입과 해당 함수를 매핑하는 딕셔너리\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n"
     ]
    }
   ],
   "source": [
    "finished = [\n",
    "    \"TPC\"\n",
    "            \n",
    "]\n",
    "\n",
    "selected_items = [i for i, feature in enumerate(feature_types) if feature not in finished]\n",
    "print(selected_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized data for lg_long has been saved to the database.\n",
      "AAC features have been saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/AAC_succ.csv\n",
      "Normalized data for AAC has been saved to the database.\n",
      "Error: for \"AAINDEX\" encoding, the input fasta sequences should be with equal length. \n",
      "\n",
      "\n",
      "Error processing AAINDEX. Details saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/AAINDEX_error.csv\n",
      "Error processing APAAC. Details saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/APAAC_error.csv\n",
      "Error: for \"BINARY\" encoding, the input fasta sequences should be with equal length. \n",
      "\n",
      "\n",
      "Error processing BINARY. Details saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/BINARY_error.csv\n",
      "Error: for \"BLOSUM62\" encoding, the input fasta sequences should be with equal length. \n",
      "\n",
      "\n",
      "Error processing BLOSUM62. Details saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/BLOSUM62_error.csv\n",
      "CKSAAGP features have been saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/CKSAAGP_succ.csv\n",
      "Normalized data for CKSAAGP has been saved to the database.\n",
      "CKSAAP features have been saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/CKSAAP_succ.csv\n",
      "Error processing CKSAAP. Details saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/CKSAAP_error.csv\n",
      "CTD_C features have been saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/CTD_C_succ.csv\n",
      "Normalized data for CTD_C has been saved to the database.\n",
      "CTD_D features have been saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/CTD_D_succ.csv\n",
      "Normalized data for CTD_D has been saved to the database.\n",
      "CTD_T features have been saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/CTD_T_succ.csv\n",
      "Normalized data for CTD_T has been saved to the database.\n",
      "CTriad features have been saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/CTriad_succ.csv\n",
      "Normalized data for CTriad has been saved to the database.\n",
      "DDE features have been saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/DDE_succ.csv\n",
      "Normalized data for DDE has been saved to the database.\n",
      "DPC features have been saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/DPC_succ.csv\n",
      "Normalized data for DPC has been saved to the database.\n",
      "Error: for \"EAAC\" encoding, the input fasta sequences should be with equal length. \n",
      "\n",
      "\n",
      "Error processing EAAC. Details saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/EAAC_error.csv\n",
      "Error: for \"EGAAC\" encoding, the input fasta sequences should be with equal length. \n",
      "\n",
      "\n",
      "Error processing EGAAC. Details saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/EGAAC_error.csv\n",
      "GAAC features have been saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/GAAC_succ.csv\n",
      "Normalized data for GAAC has been saved to the database.\n",
      "GDPC features have been saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/GDPC_succ.csv\n",
      "Normalized data for GDPC has been saved to the database.\n",
      "GTPC features have been saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/GTPC_succ.csv\n",
      "Normalized data for GTPC has been saved to the database.\n",
      "Error processing Geary. Details saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/Geary_error.csv\n",
      "Error processing Moran. Details saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/Moran_error.csv\n",
      "Error processing NMBroto. Details saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/NMBroto_error.csv\n",
      "Error processing PAAC. Details saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/PAAC_error.csv\n",
      "Error processing QSOrder. Details saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/QSOrder_error.csv\n",
      "Error processing SOCNumber. Details saved to: /Users/kimsohui/Project/bioinformatics/Data/SH/lg_long_90_if/SOCNumber_error.csv\n",
      "\n",
      "\n",
      "[ Succed iFeature ]\n",
      "AAC\n",
      "CKSAAGP\n",
      "CKSAAP\n",
      "CTD_C\n",
      "CTD_D\n",
      "CTD_T\n",
      "CTriad\n",
      "DDE\n",
      "DPC\n",
      "GAAC\n",
      "GDPC\n",
      "GTPC\n"
     ]
    }
   ],
   "source": [
    "note = '''\n",
    "\n",
    "\"\" save to db iFeature nomalization \"\"\n",
    "---------------------------------------------------------------\n",
    "\n",
    "amp_file : 분석하고자 하는 파일 이름 (확장자명 제외)\n",
    "amp_folder : 분석하고자 하는 파일이 들어있는 폴더 이름 (SH 안)\n",
    "\n",
    "feature_save_folder : 추출한 특징을 저장하고자 하는 폴더 이름 (SH 안)\n",
    "\n",
    "nor_db_name : 저장하고자 하는 DB 스키마명, DB에서 스키마를 만든 후 실행하면 됨\n",
    "\n",
    "'''\n",
    "\n",
    "'''-----------------------------------------------------------'''\n",
    "\n",
    "amp_file            = 'lg_long'\n",
    "amp_folder          = 'amp_90'\n",
    "\n",
    "feature_save_folder = 'lg_long_90_if'\n",
    "\n",
    "nor_db_name         = 'lg_long_90_if' \n",
    "\n",
    "'''-----------------------------------------------------------'''\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 데이터베이스 설정 정보\n",
    "host = '127.0.0.1'\n",
    "user = 'root'\n",
    "password = ''\n",
    "charset = 'utf8mb4'\n",
    "    \n",
    "# SQLAlchemy 엔진 생성\n",
    "engine = create_engine(f\"mysql+pymysql://{user}:{password}@{host}/{nor_db_name}?charset={charset}\")\n",
    "\n",
    "succeed = []\n",
    "\n",
    "\n",
    "def save_to_db(feature_name, featureCSV_dir, clusted):\n",
    "    csv_file_path = os.path.join(featureCSV_dir, f\"{feature_name}{clusted}.csv\")\n",
    "    data = pd.read_csv(csv_file_path)\n",
    "    if clusted == \"_succ\" :\n",
    "        scaler = MinMaxScaler()\n",
    "        columns_to_scale = data.columns.drop('Seq')  # 'Seq' 컬럼 제외하여 정규화 진행\n",
    "        data[columns_to_scale] = scaler.fit_transform(data[columns_to_scale])\n",
    "    \n",
    "    data.to_sql(name=feature_name, con=engine, if_exists='replace', index=False)\n",
    "    print(f\"Normalized data for {feature_name} has been saved to the database.\")\n",
    "\n",
    "def main():    \n",
    "    \n",
    "    fasta_file = f'{amp_folder}/{amp_file}.fasta'  # FASTA 파일 경로\n",
    "    ampCSV_dir = f'{amp_folder}'  # FASTA 파일 경로\n",
    "    featureCSV_dir = f'{feature_save_folder}'  # 결과 파일을 저장할 디렉토리\n",
    "\n",
    "    # amp csv 파일 저장\n",
    "    save_to_db(amp_file, ampCSV_dir, \"\")\n",
    "    \n",
    "    # fasta 파일 읽기\n",
    "    fastas = readFasta(fasta_file)\n",
    "    \n",
    "    for index in selected_items:\n",
    "        feature_name = feature_types[int(index)]\n",
    "        \n",
    "        try:\n",
    "            encodings = FEATURE_FUNCTIONS[feature_name](fastas)\n",
    "            output_file = os.path.join(featureCSV_dir, f\"{feature_name}_succ.csv\")\n",
    "            \n",
    "            with open(output_file, 'w', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                first_row = True\n",
    "                for encoding in encodings:\n",
    "                    if first_row:\n",
    "                        encoding[0] = 'Seq'  # 첫 번째 행의 첫 번째 컬럼을 'Seq'로 변경\n",
    "                        first_row = False\n",
    "                    else:\n",
    "                        # 시퀀스 문자열의 끝에 콤마가 있는지 확인하고 제거\n",
    "                        seq = encoding[0]\n",
    "                        if seq.endswith(','):\n",
    "                            encoding[0] = seq[:-1]\n",
    "                    writer.writerow(encoding)\n",
    "            \n",
    "            print(f\"{feature_name} features have been saved to: {output_file}\")\n",
    "            succeed.append(feature_name)\n",
    "            save_to_db(feature_name, featureCSV_dir, \"_succ\")  # 성공한 특징을 데이터베이스에 저장\n",
    "            \n",
    "\n",
    "        except Exception as e:\n",
    "            if os.path.exists(output_file):\n",
    "                os.remove(output_file)\n",
    "            \n",
    "            error_file = os.path.join(featureCSV_dir, f\"{feature_name}_error.csv\")\n",
    "            with open(error_file, 'w', newline='') as csvfile:\n",
    "                writer = csv.writer(csvfile)\n",
    "                writer.writerow(['Error'])\n",
    "                writer.writerow([str(e)])\n",
    "            \n",
    "            print(f\"Error processing {feature_name}. Details saved to: {error_file}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    \n",
    "print(\"\\n\\n[ Succed iFeature ]\")\n",
    "for name in succeed:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AAindex\n",
    "\n",
    "# -*- coding: ms949 -*-\n",
    "import MyUtil\n",
    "import copy\n",
    "import DBPATH\n",
    "\n",
    "# 아미노산 순서 정의\n",
    "AA_ORDER1 = [ 'A', 'R', 'N', 'D', 'C', 'Q', 'E', 'G', 'H', 'I' ]\n",
    "AA_ORDER2 = [ 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V'  ]\n",
    "\n",
    "'''\n",
    "AAIndex2와 AAIndex3은 다른 파일에서 처리될 예정임을 나타냅니다.\n",
    "'''\n",
    "\n",
    "class AAIndex1:\n",
    "\n",
    "\tpath = DBPATH.DB_PATH + '/AAindex/aaindex1.txt'\n",
    "\tbox = {}\n",
    "\n",
    "\tdef __init__(self):\n",
    "\t\tself.box = {}\n",
    "\t\tself.__load(self.path)\n",
    "\n",
    "\t# 박스에 저장된 속성의 개수를 반환합니다.\n",
    "\tdef getPropertySize(self):\n",
    "\t\treturn len(self.box)\n",
    "\n",
    "\t# 사용 가능한 모든 속성의 이름을 반환합니다.\n",
    "\tdef getPropertyNames(self):\n",
    "\t\treturn self.box.keys()\n",
    "\n",
    "\t# 주어진 이름의 속성 값을 반환합니다.\n",
    "\tdef getPropertyOf(self, name):\n",
    "\t\treturn self.box[name]\n",
    "\n",
    "\t# 시퀀스에 대한 특정 속성의 점수를 계산합니다.\n",
    "\tdef calculatePropertyOfSequence(self, name, sequence):\n",
    "\t\tsequence = sequence.strip()\n",
    "\t\tprop = self.getPropertyOf(name)\n",
    "\t\tscore = 0\n",
    "\t\tfor a in sequence:\n",
    "\t\t\tscore += prop[a]\n",
    "\t\treturn score\n",
    "\t\n",
    "\t# 시퀀스에 대한 특정 속성의 정규화된 점수를 계산합니다.\n",
    "\tdef calculateNormalizedPropertyOfSequence(self, name, sequence):\n",
    "\t\tsequence = sequence.strip()\n",
    "\t\tscore = self.calculatePropertyOfSequence(name, sequence)\n",
    "\t\treturn score / len(sequence)\n",
    "\n",
    "\t# 파일에서 데이터를 로드하는 내부 메서드입니다.\n",
    "\tdef __load(self, fname):\n",
    "\n",
    "\t\tself.box = {}\n",
    "\t\tf=open(fname,'r')\n",
    "\n",
    "\t\tname = None\n",
    "\t\ttmp = {}\n",
    "\t\tindex = -1\n",
    "\n",
    "\t\tfor s in f.readlines():\n",
    "\n",
    "\t\t\ts = s.replace('\\n', '')\n",
    "\n",
    "\t\t\tif len(s)>0:\n",
    "\t\t\t\tif s[:2] == '//':  # 파일의 끝을 나타냅니다.\n",
    "\t\t\t\t\tif name is not None:\n",
    "\t\t\t\t\t\t# 이전에 처리한 속성을 box에 저장합니다.\n",
    "\t\t\t\t\t\tself.box[name] = copy.copy(tmp)\n",
    "\n",
    "\t\t\t\t\t\tname = None\n",
    "\t\t\t\t\t\ttmp = {}\n",
    "\t\t\t\t\t\tindex=-1\n",
    "\n",
    "\t\t\t\telif s[0] == 'D':  # 속성 이름의 시작을 나타냅니다.\n",
    "\t\t\t\t\tname = s[1: s.find('(')].strip()  # 속성 이름을 추출합니다.\n",
    "\t\t\t\t\tname = name.replace(' ', '_')\n",
    "\n",
    "\t\t\t\telif index == 1:\n",
    "\t\t\t\t\t# 두 번째 아미노산 순서에 대한 속성 값을 처리합니다.\n",
    "\t\t\t\t\ts = s.strip()\n",
    "\t\t\t\t\tx = s.split(' ')\n",
    "\t\t\t\t\ti = 0\n",
    "\t\t\t\t\tfor v in x:\n",
    "\t\t\t\t\t\tif len(v) != 0:\n",
    "\t\t\t\t\t\t\tif v == 'NA':  # 값이 없는 경우, 처리를 중단합니다.\n",
    "\t\t\t\t\t\t\t\tname = None\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t# 값이 있는 경우, tmp에 저장합니다.\n",
    "\t\t\t\t\t\t\t\ttmp[ AA_ORDER2[i] ] = eval(v)\n",
    "\t\t\t\t\t\t\t\ti += 1\n",
    "\t\t\t\t\tindex = -1\n",
    "\n",
    "\t\t\t\telif index == 0:\n",
    "\t\t\t\t\t# 첫 번째 아미노산 순서에 대한 속성 값을 처리합니다.\n",
    "\t\t\t\t\ts = s.strip()\n",
    "\t\t\t\t\tx = s.split(' ')\n",
    "\t\t\t\t\ti = 0\n",
    "\t\t\t\t\tfor v in x:\n",
    "\t\t\t\t\t\tif len(v) != 0:\n",
    "\t\t\t\t\t\t\tif v == 'NA':  # 값이 없는 경우, 처리를 중단합니다.\n",
    "\t\t\t\t\t\t\t\tname = None\n",
    "\t\t\t\t\t\t\t\tbreak\n",
    "\t\t\t\t\t\t\telse:\n",
    "\t\t\t\t\t\t\t\t# 값이 있는 경우, tmp에 저장합니다.\n",
    "\t\t\t\t\t\t\t\ttmp[ AA_ORDER1[i] ] = eval(v)\n",
    "\t\t\t\t\t\t\t\ti += 1\n",
    "\n",
    "\t\t\t\t\tindex = 1\n",
    "\n",
    "\t\t\t\telif s[0] == 'I':\n",
    "\t\t\t\t\tindex = 0\n",
    "\n",
    "\t\tf.close()\n",
    "\n",
    "# 메인 실행 블록\n",
    "if __name__ =='__main__':\n",
    "\ti1 = AAIndex1()\n",
    "\tprint i1.getPropertySize()  # 저장된 속성의 크기를 출력합니다.\n",
    "\tfor p in i1.getPropertyNames():  # 사용 가능한 모든 속성 이름을 출력합니다.\n",
    "\t\tprint(p)\n",
    "\t\n",
    "\t# 'Positive_charge' 속성에 대한 정보를 출력합니다.\n",
    "\tprint(i1.getPropertyOf('Positive_charge'))  \n",
    "\t# 주어진 시퀀스에 대해 'Positive_charge' 속성의 점수를 계산하여 출력합니다.\n",
    "\tprint(i1.calculatePropertyOfSequence('Positive_charge', 'AACCCIIIEERRRPPPIILLQQWWEEE'))\n",
    "\t# 주어진 시퀀스에 대해 'Positive_charge' 속성의 정규화된 점수를 계산하여 출력합니다.\n",
    "\tprint(i1.calculateNormalizedPropertyOfSequence('Positive_charge', 'AACCCIIIEERRRPPPIILLQQWWEEE'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "import csv\n",
    "from AAIndex1 import AAIndex1  # AAIndex1 클래스를 가져옵니다.\n",
    "\n",
    "# MySQL 데이터베이스 연결 설정\n",
    "db_config = {\n",
    "    'user': 'your_username',\n",
    "    'password': 'your_password',\n",
    "    'host': 'localhost',\n",
    "    'database': 'your_database_name'\n",
    "}\n",
    "\n",
    "# AAIndex1 인스턴스 생성\n",
    "aaindex = AAIndex1()\n",
    "\n",
    "# 분석할 특성 이름\n",
    "property_name = 'Positive_charge'\n",
    "\n",
    "# CSV 파일로 저장할 데이터 준비\n",
    "csv_data = [['Sequence', property_name, property_name + '_normalized']]\n",
    "\n",
    "# MySQL 데이터베이스 연결\n",
    "conn = mysql.connector.connect(**db_config)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# 펩타이드 시퀀스를 가져올 SQL 쿼리\n",
    "query = \"SELECT sequence_column FROM your_sequence_table\"\n",
    "\n",
    "try:\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    # 모든 시퀀스를 가져와서 각 시퀀스에 대해 특성 값을 계산\n",
    "    for (sequence,) in cursor:\n",
    "        property_value = aaindex.calculatePropertyOfSequence(property_name, sequence)\n",
    "        normalized_property_value = aaindex.calculateNormalizedPropertyOfSequence(property_name, sequence)\n",
    "        csv_data.append([sequence, property_value, normalized_property_value])\n",
    "\n",
    "finally:\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "\n",
    "# CSV 파일 저장\n",
    "with open('peptide_properties.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(csv_data)\n",
    "\n",
    "print('CSV file saved with peptide properties.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyterE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
